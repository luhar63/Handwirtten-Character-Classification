{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from HWCRUtils import HWCRUtils\n",
    "from Train import Train_Manager\n",
    "from Test import Test_Manager\n",
    "from CNN import Network\n",
    "\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train\n",
      "(6400,)\n",
      "(50, 49)\n",
      "(6400,)\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "data_train = np.load('train_data.pkl', allow_pickle=True)\n",
    "print(\"data_train\")\n",
    "print(data_train.shape)\n",
    "nd_arr = np.array(data_train[0])\n",
    "print(nd_arr.shape)\n",
    "\n",
    "labels = np.load('finalLabelsTrain.npy', allow_pickle=False)\n",
    "print(labels.shape)\n",
    "print(labels[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HandWrittenRecognitionDeep:\n",
    "    def __init__(self):\n",
    "        self.__train_set = None\n",
    "        self.__test_set = None\n",
    "        self.__validation_set = None\n",
    "        self.__test_set_size = None\n",
    "        self.__validation_set_size = None\n",
    "\n",
    "    def perform_hand_written_char_recognition(self, data_set_path, label_set_path, image_dims, parameters, split_size,\n",
    "                                              epochs=10):\n",
    "        self.__split_train_test_validation_set(data_set_path, label_set_path, image_dims, split_size)\n",
    "        network = self.__train_model(parameters, epochs)\n",
    "        return network\n",
    "        \n",
    "    def test_hand_written_char_recognition(self, parameters, network):\n",
    "         self.__test_model(network, parameters)  \n",
    "\n",
    "    def __split_train_test_validation_set(self, data_set_path, label_set_path, image_dims, split_size):\n",
    "        train_data_set, labels_set = HWCRUtils.read_dataset(data_set_path, label_set_path, image_dims)\n",
    "        X_train, X_test, Y_train, Y_test = HWCRUtils.spilt_data_set(train_data_set,\n",
    "                                                                    labels_set,\n",
    "                                                                    split_size=split_size)\n",
    "        X_train, X_val, Y_train, Y_val = HWCRUtils.spilt_data_set(X_train,\n",
    "                                                                  Y_train,\n",
    "                                                                  split_size=split_size)\n",
    "        train_set = HWCRUtils.convert_to_tensor(X_train, Y_train)\n",
    "        test_set = HWCRUtils.convert_to_tensor(X_test, Y_test)\n",
    "        val_set = HWCRUtils.convert_to_tensor(X_val, Y_val)\n",
    "\n",
    "        self.__train_set = train_set\n",
    "        self.__test_set = test_set\n",
    "        self.__validation_set = val_set\n",
    "        self.__test_set_size = Y_test.shape[0]\n",
    "        self.__validation_set_size = Y_test.shape[0]\n",
    "\n",
    "    def __train_model(self, parameters, epochs=10):\n",
    "        train = Train_Manager()\n",
    "        network = Network()\n",
    "        response = train.train_data_set(self.__train_set, network,\n",
    "                                        HWCRUtils.get_runs(parameters)[0],\n",
    "                                        epochs)\n",
    "        return response[\"network\"]\n",
    "\n",
    "    def __test_model(self, network, parameters):\n",
    "        test = Test_Manager()\n",
    "        ret = test.test_data_set(self.__validation_set, network, HWCRUtils.get_runs(parameters)[0])\n",
    "        percnt_correct = (ret['total_correct'] / self.__test_set_size) * 100\n",
    "        print(f\"total loss test: {ret['total_loss']}\")\n",
    "        print(f\"correctly predicted: {ret['total_correct']}\")\n",
    "        print(f\"actual correct: {self.__test_set_size}\")\n",
    "        print(f\"% correct: {percnt_correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from pkl\n",
      "training starts now\n",
      "epoch: 0, total_correct: 4190, actual_correct: 6272, % correct: 66.80484693877551, loss: 75.91474455595016\n",
      "epoch: 1, total_correct: 5433, actual_correct: 6272, % correct: 86.62308673469387, loss: 24.95569597184658\n",
      "epoch: 2, total_correct: 5777, actual_correct: 6272, % correct: 92.1077806122449, loss: 14.833492986857891\n",
      "epoch: 3, total_correct: 5936, actual_correct: 6272, % correct: 94.64285714285714, loss: 10.268797885626554\n",
      "epoch: 4, total_correct: 5986, actual_correct: 6272, % correct: 95.44005102040816, loss: 8.42610185034573\n",
      "epoch: 5, total_correct: 6013, actual_correct: 6272, % correct: 95.87053571428571, loss: 7.370262671262026\n",
      "epoch: 6, total_correct: 6041, actual_correct: 6272, % correct: 96.31696428571429, loss: 6.739381009712815\n",
      "epoch: 7, total_correct: 6102, actual_correct: 6272, % correct: 97.28954081632652, loss: 5.1121900994330645\n",
      "epoch: 8, total_correct: 6145, actual_correct: 6272, % correct: 97.9751275510204, loss: 3.6296490747481585\n",
      "epoch: 9, total_correct: 6144, actual_correct: 6272, % correct: 97.95918367346938, loss: 3.5978097980841994\n",
      "epoch: 10, total_correct: 6134, actual_correct: 6272, % correct: 97.79974489795919, loss: 3.927148764487356\n",
      "epoch: 11, total_correct: 6154, actual_correct: 6272, % correct: 98.1186224489796, loss: 3.3466144716367126\n",
      "epoch: 12, total_correct: 6149, actual_correct: 6272, % correct: 98.03890306122449, loss: 3.464792496524751\n",
      "epoch: 13, total_correct: 6179, actual_correct: 6272, % correct: 98.5172193877551, loss: 2.8811272704042494\n",
      "epoch: 14, total_correct: 6177, actual_correct: 6272, % correct: 98.48533163265306, loss: 2.609218215569854\n",
      "epoch: 15, total_correct: 6193, actual_correct: 6272, % correct: 98.74043367346938, loss: 2.607716240105219\n",
      "epoch: 16, total_correct: 6181, actual_correct: 6272, % correct: 98.54910714285714, loss: 2.924342240439728\n",
      "epoch: 17, total_correct: 6202, actual_correct: 6272, % correct: 98.88392857142857, loss: 2.381966879358515\n"
     ]
    }
   ],
   "source": [
    "data_set_path = \"train_data.pkl\"\n",
    "label_set_path = \"finalLabelsTrain.npy\"\n",
    "image_dims = (52, 52)\n",
    "epochs = 18\n",
    "split_size = 0.01\n",
    "parameters = OrderedDict(\n",
    "    lr=[0.01],\n",
    "    batch_size=[100]\n",
    ")\n",
    "\n",
    "hwRD = HandWrittenRecognitionDeep()\n",
    "network = hwRD.perform_hand_written_char_recognition(data_set_path, label_set_path, image_dims, parameters, split_size,\n",
    "                                               epochs)\n",
    "#     hwRD.test_hand_written_char_recognition(parameters, network,\n",
    "#                                               epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss test: 0.3359124958515167\n",
      "correctly predicted: 55\n",
      "actual correct: 64\n",
      "% correct: 85.9375\n"
     ]
    }
   ],
   "source": [
    "hwRD.test_hand_written_char_recognition(parameters, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (out): Linear(in_features=1024, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
