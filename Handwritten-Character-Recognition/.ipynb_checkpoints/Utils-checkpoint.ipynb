{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "from HWCRUtils import HWCRUtils\n",
    "from Train import Train_Manager\n",
    "from Test import Test_Manager\n",
    "from CNN import Network\n",
    "\n",
    "\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_train\n",
      "(6400,)\n",
      "(50, 49)\n",
      "(6400,)\n",
      "3.0\n"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "data_train = np.load('train_data.pkl', allow_pickle=True)\n",
    "print(\"data_train\")\n",
    "print(data_train.shape)\n",
    "nd_arr = np.array(data_train[0])\n",
    "print(nd_arr.shape)\n",
    "\n",
    "labels = np.load('finalLabelsTrain.npy', allow_pickle=False)\n",
    "print(labels.shape)\n",
    "print(labels[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class HandWrittenRecognitionDeep:\n",
    "    def __init__(self):\n",
    "        self.__train_set = None\n",
    "        self.__test_set = None\n",
    "        self.__validation_set = None\n",
    "        self.__test_set_size = None\n",
    "        self.__validation_set_size = None\n",
    "\n",
    "    def perform_hand_written_char_recognition(self, data_set_path, label_set_path, image_dims, parameters, split_size,\n",
    "                                              epochs=10):\n",
    "        self.__split_train_test_validation_set(data_set_path, label_set_path, image_dims, split_size)\n",
    "        network = self.__train_model(parameters, epochs)\n",
    "        return network\n",
    "        \n",
    "    def test_hand_written_char_recognition(self, parameters, network):\n",
    "         self.__test_model(network, parameters)  \n",
    "\n",
    "    def __split_train_test_validation_set(self, data_set_path, label_set_path, image_dims, split_size):\n",
    "        train_data_set, labels_set = HWCRUtils.read_dataset(data_set_path, label_set_path, image_dims)\n",
    "        X_train, X_test, Y_train, Y_test = HWCRUtils.spilt_data_set(train_data_set,\n",
    "                                                                    labels_set,\n",
    "                                                                    split_size=split_size)\n",
    "        X_train, X_val, Y_train, Y_val = HWCRUtils.spilt_data_set(X_train,\n",
    "                                                                  Y_train,\n",
    "                                                                  split_size=split_size)\n",
    "        train_set = HWCRUtils.convert_to_tensor(X_train, Y_train)\n",
    "        test_set = HWCRUtils.convert_to_tensor(X_test, Y_test)\n",
    "        val_set = HWCRUtils.convert_to_tensor(X_val, Y_val)\n",
    "\n",
    "        self.__train_set = train_set\n",
    "        self.__test_set = test_set\n",
    "        self.__validation_set = val_set\n",
    "        self.__test_set_size = Y_test.shape[0]\n",
    "        self.__validation_set_size = Y_test.shape[0]\n",
    "\n",
    "    def __train_model(self, parameters, epochs=10):\n",
    "        train = Train_Manager()\n",
    "        network = Network()\n",
    "        response = train.train_data_set(self.__train_set, network,\n",
    "                                        HWCRUtils.get_runs(parameters)[0],\n",
    "                                        epochs)\n",
    "        return response[\"network\"]\n",
    "\n",
    "    def __test_model(self, network, parameters):\n",
    "        test = Test_Manager()\n",
    "        ret = test.test_data_set(self.__validation_set, network, HWCRUtils.get_runs(parameters)[0])\n",
    "        percnt_correct = (ret['total_correct'] / self.__test_set_size) * 100\n",
    "        print(f\"total loss test: {ret['total_loss']}\")\n",
    "        print(f\"correctly predicted: {ret['total_correct']}\")\n",
    "        print(f\"actual correct: {self.__test_set_size}\")\n",
    "        print(f\"% correct: {percnt_correct}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from pkl\n",
      "training starts now\n"
     ]
    }
   ],
   "source": [
    "data_set_path = \"train_data.pkl\"\n",
    "label_set_path = \"finalLabelsTrain.npy\"\n",
    "image_dims = (52, 52)\n",
    "epochs = 18\n",
    "split_size = 0.01\n",
    "parameters = OrderedDict(\n",
    "    lr=[0.01],\n",
    "    batch_size=[100]\n",
    ")\n",
    "\n",
    "hwRD = HandWrittenRecognitionDeep()\n",
    "network = hwRD.perform_hand_written_char_recognition(data_set_path, label_set_path, image_dims, parameters, split_size,\n",
    "                                               epochs)\n",
    "#     hwRD.test_hand_written_char_recognition(parameters, network,\n",
    "#                                               epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss test: 0.3359124958515167\n",
      "correctly predicted: 55\n",
      "actual correct: 64\n",
      "% correct: 85.9375\n"
     ]
    }
   ],
   "source": [
    "hwRD.test_hand_written_char_recognition(parameters, network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(192, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "  (out): Linear(in_features=1024, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
